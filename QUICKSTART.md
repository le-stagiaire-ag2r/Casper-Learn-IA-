# üöÄ Guide de D√©marrage Rapide

## Lancement en 5 minutes

### 1. Pr√©requis

```bash
# V√©rifier Python
python --version  # Doit √™tre 3.11+

# V√©rifier pip
pip --version
```

### 2. Installation

```bash
# Installer les d√©pendances
pip install -r requirements.txt

# Cela va installer :
# - FastAPI & Uvicorn (API)
# - LangChain (RAG)
# - ChromaDB (base vectorielle)
# - BeautifulSoup (scraping)
# - OpenAI (LLM)
# - Et plus...
```

### 3. Configuration

```bash
# Copier le fichier d'environnement
cp .env.example .env

# √âditer avec votre √©diteur pr√©f√©r√©
nano .env
# ou
vim .env
# ou
code .env
```

**Ajouter votre cl√© OpenAI** :
```
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxx
```

Obtenez votre cl√© sur : https://platform.openai.com/api-keys

### 4. Scraper la documentation

```bash
python scripts/scrape_docs.py
```

**Ce que fait ce script** :
- Se connecte √† docs.cspr.cloud
- D√©couvre toutes les pages de documentation
- Extrait le contenu et les exemples de code
- Sauvegarde dans `data/docs/cspr_cloud_docs.json`

**Dur√©e** : ~2-5 minutes selon votre connexion

### 5. Indexer les documents

```bash
python scripts/index_docs.py
```

**Ce que fait ce script** :
- Charge les documents scrap√©s
- D√©coupe en chunks de 1000 caract√®res
- Cr√©e les embeddings vectoriels (all-MiniLM-L6-v2)
- Indexe dans ChromaDB
- Stocke dans `data/chromadb/`

**Dur√©e** : ~3-10 minutes selon le nombre de docs

**R√©sultat attendu** :
```
‚úÖ Indexation termin√©e: 500-1000 chunks au total
üìä 500-1000 documents dans la base vectorielle
```

### 6. Lancer l'API

```bash
python backend/api/main.py
```

**Sortie attendue** :
```
üöÄ D√©marrage de l'API Casper Learn IA...
‚úÖ RAG Engine initialis√© avec succ√®s
INFO:     Uvicorn running on http://0.0.0.0:8000
```

L'API est maintenant disponible sur :
- **API** : http://localhost:8000
- **Docs interactives** : http://localhost:8000/docs
- **Redoc** : http://localhost:8000/redoc

### 7. Ouvrir l'interface web

```bash
# Dans un navigateur, ouvrir :
firefox frontend/index.html
# ou
chrome frontend/index.html
# ou
open frontend/index.html  # macOS
```

Ou avec un serveur HTTP simple :
```bash
cd frontend
python -m http.server 3000
# Puis ouvrir http://localhost:3000
```

## üß™ Test rapide via API

### Test 1 : Health check

```bash
curl http://localhost:8000/health
```

R√©sultat attendu :
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "rag_initialized": true
}
```

### Test 2 : Poser une question

```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Comment interroger le solde d'\''un compte Casper?",
    "n_context": 5
  }'
```

R√©sultat attendu :
```json
{
  "answer": "Pour interroger le solde d'un compte Casper, vous pouvez...",
  "sources": [
    {
      "title": "Accounts API - Get Balance",
      "url": "https://docs.cspr.cloud/rest-api/accounts",
      "relevance": 0.89
    }
  ],
  "success": true
}
```

### Test 3 : Recherche s√©mantique

```bash
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "CEP-18 token standard",
    "n_results": 3
  }'
```

### Test 4 : Statistiques

```bash
curl http://localhost:8000/stats
```

## üêõ D√©pannage

### Probl√®me : "OPENAI_API_KEY non d√©finie"

**Solution** :
```bash
# V√©rifier que .env existe
cat .env

# V√©rifier que la cl√© est d√©finie
echo $OPENAI_API_KEY

# Exporter manuellement si besoin
export OPENAI_API_KEY="sk-proj-xxxxxxxx"
```

### Probl√®me : "Collection 'casper_docs' not found"

**Solution** : Vous n'avez pas index√© les documents
```bash
python scripts/index_docs.py
```

### Probl√®me : "No module named 'backend'"

**Solution** : Ajouter le r√©pertoire au PYTHONPATH
```bash
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
python backend/api/main.py
```

### Probl√®me : Le scraper ne trouve aucune page

**Solution** : Le site docs.cspr.cloud peut √™tre temporairement indisponible ou avoir chang√© de structure
- V√©rifier manuellement : https://docs.cspr.cloud/
- Adapter les URLs dans `scripts/scrape_docs.py` si n√©cessaire

### Probl√®me : CORS error dans le frontend

**Solution** : L'API FastAPI a d√©j√† CORS activ√©. V√©rifiez que :
1. L'API tourne sur le bon port (8000)
2. Le frontend pointe vers la bonne URL dans `index.html` (ligne 491)

### Probl√®me : Slow response times

**Causes possibles** :
1. **OpenAI API lente** : Normal, GPT-4 peut prendre 5-15s
2. **Trop de contextes** : R√©duire `n_context` de 5 √† 3
3. **R√©seau lent** : V√©rifier votre connexion internet

## üìä V√©rification de l'installation

Liste de contr√¥le :

- [ ] Python 3.11+ install√©
- [ ] Dependencies install√©es (`pip install -r requirements.txt`)
- [ ] `.env` cr√©√© avec `OPENAI_API_KEY`
- [ ] Documentation scrap√©e (`data/docs/cspr_cloud_docs.json` existe)
- [ ] Documents index√©s (`data/chromadb/` existe et contient des fichiers)
- [ ] API d√©marre sans erreur (`http://localhost:8000/health` retourne `healthy`)
- [ ] Frontend accessible et peut communiquer avec l'API

## üéØ Prochaines √©tapes

Une fois que tout fonctionne :

1. **Tester avec diff√©rentes questions** :
   - Questions sur les APIs
   - Questions sur les smart contracts
   - Questions sur les tokens CEP
   - Questions sur les validateurs

2. **Personnaliser le syst√®me** :
   - Ajuster la temp√©rature du LLM (backend/llm/rag_engine.py:67)
   - Changer le nombre de contextes r√©cup√©r√©s
   - Modifier le prompt syst√®me
   - Ajouter d'autres sources de documentation

3. **Am√©liorer le frontend** :
   - Ajouter un th√®me sombre
   - Historique des conversations
   - Export de conversations
   - Recherche dans l'historique

4. **Optimisations** :
   - Caching des r√©ponses fr√©quentes
   - Utiliser un LLM local (Ollama + Mistral/Llama)
   - Fine-tuning sur vos propres donn√©es

## üí° Astuces

### Activer le mode debug

```bash
# Dans backend/api/main.py, ajouter :
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Utiliser GPT-3.5 au lieu de GPT-4 (plus rapide, moins cher)

```python
# Dans backend/llm/rag_engine.py, ligne 65, remplacer :
self.llm = ChatOpenAI(
    model="gpt-3.5-turbo",  # Au lieu de gpt-4-turbo-preview
    temperature=0.3,
)
```

### Scraper d'autres sources

Cr√©ez un nouveau scraper dans `scripts/` pour :
- Documentation officielle Casper
- GitHub repos (smart contracts exemples)
- Vos 3 autres projets
- Medium articles sur Casper

### Indexer vos propres projets

```python
# Ajouter dans scripts/index_docs.py
# Apr√®s avoir index√© CSPR.cloud, indexer vos projets :
import os

project_docs = []
for root, dirs, files in os.walk('../Casper-projet/'):
    for file in files:
        if file.endswith('.md') or file.endswith('.rst'):
            with open(os.path.join(root, file)) as f:
                content = f.read()
                project_docs.append({
                    'url': f'file://{os.path.join(root, file)}',
                    'title': file,
                    'content': content,
                    'code_examples': [],
                    'source': 'casper-projet'
                })

# Puis indexer ces docs aussi
```

## üéâ Succ√®s !

Si vous √™tes arriv√©s ici, f√©licitations ! Vous avez maintenant :
- ‚úÖ Un assistant IA fonctionnel pour apprendre Casper
- ‚úÖ Une base de connaissances compl√®te et cherchable
- ‚úÖ Une API REST pour int√©grations
- ‚úÖ Une interface web interactive

**Bon hackathon ! üöÄ**
